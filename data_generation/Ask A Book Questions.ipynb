{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d615a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install tiktoken\n",
    "%pip install openai\n",
    "%pip install pypdf\n",
    "%pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3e92ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    }
   ],
   "source": [
    "# PDF Loaders. If unstructured gives you a hard time, try PyPDFLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166d759",
   "metadata": {},
   "source": [
    "### Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "\n",
    "## Other options for loaders \n",
    "# loader = UnstructuredPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "# loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcdac23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4fd7c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 126 document(s) in your data\n",
      "There are 2812 characters in your document\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then it will split by page for you already\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[30].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9b604",
   "metadata": {},
   "source": [
    "### Chunk your data up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: If you're using PyPDFLoader then we'll be splitting for the 2nd time.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879873a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 1222 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b2843",
   "metadata": {},
   "source": [
    "### Create embeddings of your documents to get ready for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373e695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\langchain-tutorials\\.venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e093ef3",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Check to see if there is an environment variable with you API keys, if not, use what you put below\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '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')\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', '15a1bab4-632b-40ee-a1ab-4c4167b1fab4')\n",
    "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'us-west4-gcp-free') # You may need to switch with your env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e0d1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0deb2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"langchain\" # put in the name of your pinecone index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "388988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)\n",
    "\n",
    "# if you already have an index, you can load it like this\n",
    "# docsearch = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34929595",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some top quotes you can list relating to data science?\"\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e0f5b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs retrieved: 4\n"
     ]
    }
   ],
   "source": [
    "# Here's an example of the first document that was returned\n",
    "print(f\"Number of docs retrieved: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35dcd9",
   "metadata": {},
   "source": [
    "### Query those docs to get your answer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f051337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b9b1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some quotes related to data science from the given context:\n",
      "\n",
      "- \"In the jungle of data, don't miss the forest for the trees, or the trees for the forest.\" - Paul Yacci\n",
      "- \"I treat Data Science like I do rock.\" - Stephanie Rivera\n",
      "- \"Data Science is about formally analyzing everything around you and becoming data-driven.\" - @ekohlwey\n",
      "- \"The best way to predict the future is to have your data tell you what it is.\" - @fchollet\n",
      "Tokens Used: 329\n",
      "\tPrompt Tokens: 223\n",
      "\tCompletion Tokens: 106\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.000658\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with get_openai_callback() as cb:\n",
    "  llm = ChatOpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)\n",
    "  chain = load_qa_chain(llm, chain_type=\"stuff\")  \n",
    "  docs = docsearch.similarity_search(query)\n",
    "  \n",
    "  print(chain.run(input_documents=docs, question=query))\n",
    "  \n",
    "  print(cb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2008e5e6",
   "metadata": {},
   "source": [
    "### Using Conversational Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16d91876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some top quotes related to data science:\n",
      "\n",
      "1. \"In God we trust. All others must bring data.\" - W. Edwards Deming\n",
      "2. \"Data is the new oil.\" - Clive Humby\n",
      "3. \"Without big data analytics, companies are blind and deaf, wandering out onto the web like deer on a freeway.\" - Geoffrey Moore\n",
      "4. \"Data science is not a magic wand that can wave away all complexity, but it is a powerful tool for gaining insights from data.\" - Cathy O'Neil\n",
      "5. \"Data is a precious thing and will last longer than the systems themselves.\" - Tim Berners-Lee\n",
      "6. \"Data science is about using data to create as much impact as possible for your company.\" - Hilary Mason\n",
      "7. \"The goal is to turn data into information, and information into insight.\" - Carly Fiorina\n",
      "8. \"Data scientists are like artists, but instead of painting or sculpting, we create models and algorithms.\" - Jake Porway\n",
      "9. \"Data science is the sexiest job of the 21st century.\" - Hal Varian\n",
      "10. \"Data is the new science. Big data holds the answers.\" - Pat Gelsinger\n",
      "As an AI language model, I don't have personal preferences or feelings, so I don't have a favorite quote. However, I can tell you that each quote has its own unique perspective on data science. For example, Paul Yacci's quote emphasizes the importance of seeing the big picture in data analysis, while Stephanie Rivera's quote compares data science to rock music. Meanwhile, @ekohlwey's quote highlights the importance of being data-driven in decision-making.\n",
      "Tokens Used: 1148\n",
      "\tPrompt Tokens: 779\n",
      "\tCompletion Tokens: 369\n",
      "Successful Requests: 3\n",
      "Total Cost (USD): $0.002296\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chat_history = []\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "  qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY), docsearch.as_retriever())\n",
    "\n",
    "  query = \"What are some top quotes you can list relating to data science?\"  \n",
    "  result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "  chat_history.append((query, result[\"answer\"]))\n",
    "  print(result[\"answer\"])\n",
    "\n",
    "  query = \"What is your top quote from from the list and why?\"  \n",
    "  result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "  chat_history.append((query, result[\"answer\"]))\n",
    "  print(result[\"answer\"])\n",
    "\n",
    "\n",
    "  print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37fb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
